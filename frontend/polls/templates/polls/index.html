<!DOCTYPE html>
{% load staticfiles %}

<html>
<head>
    <title>Caliper Report</title>
    {% load static %}
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <!-- CSS dependecies -->
    <link rel="stylesheet" type="text/css" href="{% get_static_prefix %}js/lib/bootstrap/dist/css/bootstrap.min.css"/>
    <link rel="stylesheet" type="text/css" href="{% get_static_prefix %}js/lib/pickadate/lib/themes/classic.css"/>
    <link rel="stylesheet" type="text/css" href="{% get_static_prefix %}js/lib/pickadate/lib/themes/classic.date.css"/>
    <link rel="stylesheet" type="text/css" href="{% get_static_prefix %}js/lib/fontawesome/css/font-awesome.min.css"/>
    <link rel="stylesheet" type="text/css" href="{% get_static_prefix %}js/lib/summernote/dist/summernote.css"/>

    <!-- Sensei Grid CSS -->
    <link rel="stylesheet" type="text/css" href="{% static 'polls/css/sensei-grid.css' %}"/>

    <!-- JS dependencies -->
    <script src="{% get_static_prefix %}js/lib/jquery/dist/jquery.min.js"></script>
    <script src="{% get_static_prefix %}js/lib/lodash/dist/lodash.min.js"></script>
    <script src="{% get_static_prefix %}js/lib/pickadate/lib/picker.js"></script>
    <script src="{% get_static_prefix %}js/lib/pickadate/lib/picker.date.js"></script>
    <script src="{% get_static_prefix %}js/lib/bootstrap/dist/js/bootstrap.js"></script>
    <script src="{% get_static_prefix %}js/lib/summernote/dist/summernote.js"></script>

    <!-- Sensei Grid JS -->
    <script src="{% static 'polls/js/src/sensei-grid.js' %}"></script>
    <script src="{% static 'polls/js/src/sensei-editors.js' %}"></script>
    <script src="{% static 'polls/js/src/sensei-json.js' %}"></script>
    {% if dic_sum %}
    <script src="{% static 'polls/js/example/example_test.js' %}"></script>
    {% endif %}
    <!--script src="{% static 'polls/js/example/test_tool.js' %}"></script>
    <script src="{% static 'polls/js/example/test_execution.js' %}"></script-->
    {% if perf_summary %}
    <script src="{% static 'polls/js/example/perf_sum_result.js' %}"></script>
    {% endif %}
    {% if func_summary %}
    <script src="{% static 'polls/js/example/func_sum_result.js' %}"></script>
    {% endif %}

<!-- link the caliper report css here -->
<link rel="stylesheet" type="text/css" href="../static/css/caliper_report.css"/>	
    <!-- End : Caliper Head section -->

</head>
<body>
<div class="example">
    <div><input type="hidden" id="example_tst" value="{{ dic_sum }}"> </div>

    <div class="page-header">
    <h1> Caliper Benchmarking Report [ version-yyyymmdd ] </h1> <!--SKD++-->
    </div>
    <!-- START Updating data-->
    <p>
        <b>Caliper</b> is a benchmarking framework for <b>server platforms</b>, integrated with industry standard tools
        and test cases. It provides detailed performance assessments for <b>server platforms</b> based on ARM and x86.
        The <b>uniqueness</b> of Caliper is a consolidated score based evaluation. The best performance in each test
        will get a score of 100. All other test scores are calculated relative to this. This provides a clear relative
        positioning of each target platform. It enables easy analysis of the performance levels and bottlenecks.
    </p>

    <p>
        As the performance testing can depend on system hardware resources at the time of execution, it is bound to vary
        over repeated testing. In general, this makes it difficult to analyse the performance results. Caliper tries to
        solve it for the performance analysts by executing at least <b>5 iterations of each test on every platform and
        ensure low variance</b>. This provides a more believable and stable scores throughout the report.<br>

        This version of report is prepared with:
        <mark>
            5 executions each on 8 target platforms. Each execution consists of 27 test suits collecting 2052 test
            points
            across all platforms.
        </mark>

	This gives a measure of variability for the samples with respect to the <b>Mean</b> value.
	Please click here <a href="{% static 'polls/pictures/iterative_execution.html' %}" target="_blank"> <b>Caliper Execution</b></a> for more details</p>
    </p>

	<h2> 1. Overall Assessment </h2>
    <p style="margin-left: 100px"> <!-- First level indentation-->
    <h3>1.1 Key Observation</h3>

    <font size="2" color="purple"> Please click each line below to get further information</font>


    <ul>

	<li style="color:red;">
            <a onClick="MyWindow=window.open('./index.html#Performance Score',width=50,height=50); return false;">
                <font color="red">
                    Add your observation here one by one. Update the onClick parameter.
                </font>
            </a>
	</li>
    </ul>

    <h3>1.2 Tested Platforms</h3>
    <div id="platform_configuration" class="sensei-grid"></div> 
    <i><b>Attn: </b>Please <b>scroll to right</b> to see the table completely. Same with other tables in this report</i><br>
    <i><b>arm_64 Core is ARM-v8, Cortex A72 </b>  </i><br><br>
   
    <ul>

        <li><b>Hardware details </b>:</li>

Please give link to hardware_info logs of each platform here

    </ul>
  <h3> 1.3 Functional Score Summary</h3>

    {% if func_summary %}
    <h2>Caliper Functional Test Score</h2>
    
    <p>Caliper does basic functional verification on the target platforms. It also creates the scores based on the pass rate of functional tests on each platform. Currently caliper categorizes the functional tests under <a href="/polls/kernel" target="_blank">KERNEL</a> and <a href="/polls/debug" target="_blank">DEBUG</a>(please click the link for each category details)
    </p>

	<div style="text-align: center;">
        <p> <img src="{% static 'polls/pictures/Functional_Total_Scores.png' %}" height="400"
        width="600" /> </p>
	</div>
    
    <div id="sum_func_info" class="sensei-grid"></div>
    {% endif %}


    <h3>1.4 Performance Score Summary</h3>
    {% if perf_summary %}

	<div style="text-align: center;">
        <p> <img src="{% static 'polls/pictures/Performance_Total_Scores.png' %}" height="700"
        width="700" /> </p>
	</div>
    
    <div id="sum_perf_info" class="sensei-grid"></div>
    <!--changing the endif position of  Performance Test Score to generate "The test data" part
    for both Functional and Performance during web report generatioin-->
     {% endif %}
    </div>

<h2>2. Detailed Assessment </h2>

<h3>2.1 Performance </h3>

<ul>

    <li><b>Test Categories :</b>
        <i>
            <a href="polls/latency.html" target="_blank">LATENCY</a>,
            <a href="polls/memory.html" target="_blank">MEMORY</a>,
            <a href="polls/application.html" target="_blank"> APPLICATION</a>,
            <a href="polls/cpu_multicore.html" target="_blank">CPU_MULTICORE</a>,
            <a href="polls/storage.html" target="_blank">STORAGE</a>,
            <a href="polls/cpu_sincore.html" target="_blank">CPU_SINCORE</a>,
            <a href="polls/algorithm.html" target="_blank">ALGORITHM</a> and
            <a href="polls/network.html" target="_blank">NETWORK</a>
        </i>
    </li>

    <li><b>Consolidated Test Results:</b> <a href="static/TestInfo/Report-Data/Performance-Tests.xlsx" target="_blank">
        <i>Gives the actual test results from each test cases</i></a>

</ul>


<h2>3. Documentation:</h2>
<ul>
    <li>
        <a href="https://github.com/open-estuary/caliper/blob/master/doc/Caliper_User_Manual.pdf" > <i>Caliper user manuel</i> </a>
    </li>
    <li>
        <a href="./static/polls/pictures/score_Calculation.html" target="_blank"> <i>Caliper Scoring - HowTo</i></a>
    </li>

    <li><a href="./static/TestInfo/Tool_details.xlsx" target="_blank"> <i>List of tools</i> </a></li>


    <li id="Change log">Changelog [ version-yyyymmdd ]</li>

    <ol type="a">
        <li>
            New tools and new test cases has been added as per sailing report:
            <a href="./static/polls/pictures/Caliper_Test_Cases.html" target="_blank">Caliper Test Cases</a>
        </li>

        <li>
            Table alignment has been changed to support nginx and redis test cases.
        </li>

    </ol>


</ul>


<h2>4. Disclaimers:</h2>
<ul>
    <li>
        Caliper scores are not actual test results but they are derived from the actual values using some specific
        algoritms.
    <li>
        Caliper benchmark scores can depend on the system conditions and resources at the time of execution. However
        Caliper execute atleast 5 iterations of each test to ensure the repeatability and authenticity of the scores.
    </li>
</ul>

<div style="text-align: center;">
<dl id="copyright">
    <dt title="Copyright">&copy;</dt>
    <dd><a href="http://www.open-estuary.org" target="_blank">Open Estuary</a></dd>
</dl>
</div>
</body>
</html>
