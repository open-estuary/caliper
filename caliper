#!/usr/bin/env python
# -*- coding:utf-8 -*-

import pdb
import os
import re
import sys
import time
import logging
import shutil
import signal
import datetime
import commands
import subprocess
import glob
import ConfigParser
import getpass
import yaml

from argparse import ArgumentParser

from caliper.client.parser.dictionary import openssl
from caliper.client.shared.caliper_path import folder_ope as FOLDER
try:
    import caliper.common as common
except ImportError:
    import common

from caliper.server.build import build
from caliper.server.run import test_run
from caliper.server.run import write_results
from caliper.client.shared.settings import settings
from caliper.client.shared import error
from caliper.server.hosts import host_factory
from caliper.client.shared import caliper_path
from caliper.client.shared import utils
from caliper.client.shared import send_mails
from caliper.server import summary
from caliper.server.parser_process import parser as parser_engine
from caliper.server.parser_process import normalize
from caliper.server.parser_process import openssl
from caliper.server.parser_process import hardware
from caliper.server.parser_process import performance_functional
from caliper.client.shared.caliper_path import intermediate

from caliper.upload import upload


def build_all_tests(remote_host,f_option,clear):
    try:
        logging.info("Begining to build Caliper for the remote host")
        result1 = build.build_for_target(remote_host,f_option,clear)
    except Exception, e:
        logging.info(e)
        raise
    else:
        return result1

def populate_excels():
    template_dir = caliper_path.TEMPLATE_DATA_DIR
    input_cov = caliper_path.COV_DATA_DIR_INPUT
    output_cov = caliper_path.COV_DATA_DIR_OUTPUT
    input_path = caliper_path.CONSOLIDATED_DATA_DIR_INPUT
    output_path = caliper_path.EXCEL_DATA_DIR_OUTPUT
    file_list = []

    Iteration_len = 0

    col = performance_functional.col_start

    cov_files_list = performance_functional.get_cov_file_list(input_cov)

    if cov_files_list:
        Iteration_len = len(cov_files_list[0])

    for item in cov_files_list:
        file_name = ".".join(item[0].split("/")[-1].split(".")[0:-1])
        output_excel_path = os.path.join(output_cov, file_name)
        if not os.path.exists(output_excel_path):
            os.makedirs(output_excel_path)
        try:
            col_end = performance_functional.populate_excel(item, output_excel_path, template_dir,1)
            performance_functional.mean_cov_populate( output_excel_path, col_end,file_name)#for each platforms in the Input_Cov folder generate the Iteration excel
            performance_functional.get_COV_excel(output_excel_path,file_name,output_cov,col,template_dir,Iteration_len)#copy the COV values to final COV excel
        except Exception as e:
            logging.info(e)
        col += 1

    for files in glob.glob(os.path.join(input_path, "*yaml")):
        file_list.append(files)
    col_end = performance_functional.populate_excel(file_list,output_path,template_dir,0)

    try:
       openssl.populate_excel()
       hardware.populate_excel()
    except Exception as e:
       logging.info(e)

def run_caliper(f_option):
    try:
        logging.debug("begining to run Caliper")
        result = test_run.run_caliper_tests(f_option)
    except Exception, e:
        print e
        logging.info("There is wrong when running Caliper")
        raise
    else:
        return result

def parser_caliper_logs(f_option):
    try:
        logging.debug("begining to Parse Caliper Logs")
        result = test_run.parser_caliper_tests(f_option)
    except Exception, e:
        print e
        logging.info("There is wrong when parsing Caliper")
        raise
    else:
        return result

def parser_caliper(remote_host):
    try:
        logging.debug("begining to parser the result of caliper")
        parser_engine.parser_caliper(remote_host)
    except Exception, e:
        logging.info("There is wrong when parsering the caliper result")
        raise

def copy_yaml(remote_host):
    '''
    copy yaml to corresponding dirs under caliper_output
    :param remote_host: target machine
    :return: None
    '''
    try:
        logging.debug("begining to copy the result of caliper")
        parser_engine.copy_file(remote_host)
    except Exception, e:
        logging.info("There is wrong when copy the caliper result")

def get_remote_url():
    try:
        server_num = settings.get_value('Caliperweb', 'server_num', type=int)
    except Exception, e:
        server_num = 0
    try:
        server_ip1 = settings.get_value('Caliperweb', 'server_ip1', type=str)
    except Exception, e:
        server_ip1 = ""
    return server_ip1

def get_remote_host():
    client_ip = '127.0.0.1'
    port = 22
    user = getpass.getuser()
    password = ''

    remote_host = host_factory.create_host(client_ip, user, password, port)
    return remote_host

def kill_django(pid):
    children = commands.getoutput("ps --ppid=%d -o pid=" % pid).split()
    for child in children:
        children1 = commands.getoutput("ps --ppid=%d -o pid=" %
                int(child)).split()
        for child1 in children1:
            utils.safe_kill(child1, signal.SIGINT)
        utils.safe_kill(child, signal.SIGSTOP)
    utils.kill_process_tree(pid)
RESULT_DIR = caliper_path.folder_ope.results_dir

def generate_web_tar():
    newpid = os.fork()
    logging.debug("the pid number is %d" % newpid)
    #child process
    if newpid == 0:
        return_code = 0
        try:
            subprocess.call( "cd %s; python manage.py migrate --fake; cd -" %
                    caliper_path.FRONT_END_DIR, shell=True )
            return_code = subprocess.call("cd %s; python\
                    manage.py runserver 8001 --noreload 1>/dev/null 2>&1 & " %
                    caliper_path.FRONT_END_DIR, shell=True)
        except Exception as e:
            raise e
        else:
            os._exit(return_code)
    else: # parent process
        time.sleep(10)
        logging.debug("the parent pid of parent is %d" % os.getpid())
        try:
            logging.info("Generating the webpages which are test results")
            subprocess.call("wget -r -p -k -np\
                    http://127.0.0.1:8001 -P %s -q" % RESULT_DIR,
                    shell=True)
            test_dir = os.path.join(RESULT_DIR, 'test_results')
            if os.path.exists( test_dir ):
                shutil.rmtree(test_dir)
            test_dir = os.path.join(RESULT_DIR, 'test_results.tar.gz')
            if os.path.exists( test_dir ):
                try:
                    shutil.rmtree(test_dir)
                except:
                    os.remove(test_dir)
            subprocess.call("cd %s; mv 127.0.0.1:8001 test_results; tar\
                    czf test_results.tar.gz test_results; rm -fr\
                    test_results" % RESULT_DIR, shell=True)
        except Exception as e:
            print e
            logging.info("There is wrong with generating the test result webpage")
            kill_django(newpid)
            return 0
        else:
            logging.info("Finishing generating the test result webpage")
            kill_django(newpid)
            return 1

def normalize_scores():
    write_results.yaml_filter(caliper_path.HTML_DATA_DIR_INPUT)
    return

def read_config():
    config_files = os.path.join(caliper_path.config_files.config_dir, 'cases_config.json')
    fp = open(config_files, 'r')
    tool_list = []
    run_case_list = []
    case_list = yaml.load(fp.read())
    for dimension in case_list:
        for i in range(len(case_list[dimension])):
            for tool in case_list[dimension][i]:
                for case in case_list[dimension][i][tool]:
                    if case_list[dimension][i][tool][case][0] == 'enable':
                        tool_list.append(tool)
                        run_case_list.append(case)
    sections = list(set(tool_list))
    return sections, run_case_list

if __name__=="__main__":
    parser = ArgumentParser(version=common.VERSION)
    parser.add_argument("-b", "--build", action="store_true",
            dest="build", default=True,help="select to incrementally build the selected test tools")
    parser.add_argument("-B", "--nobuild", action="store_false",
            dest="build", help="select not to incrementally build process of test tools")
    parser.add_argument("-c", "--cleanbuild", action="store_true",
            dest="cleanbuild", help="select to clean build the selected tools")
    parser.add_argument("-r", "--run", action="store_true", dest="run", default=True,
            help="select to run the selected test tools")
    parser.add_argument("-R", "--norun", action="store_false", dest="run", help=
            "not to execute the process of running test tools")
    parser.add_argument("-p", "--parse", action="store_true", dest="parse", default=True,
                        help="select to Parse the selected test tools")
    parser.add_argument("-P", "--noparse", action="store_false", dest="parse", help=
            "not to Parse the process of running test tools")
    parser.add_argument("-s", "--score", action="store_true", dest="score", default=True,
                        help="select to Score the selected test tools")
    parser.add_argument("-S", "--noscore", action="store_false", dest="score", help=
                        "not to Score the process of running test tools")
    parser.add_argument("-w", "--webpage", action="store_true", dest="webpage", default=False,
            help="select to generate the webpage test report")
    parser.add_argument("-e", "--email", action="store_true", dest="send_email",
            default=False, help="Select to send mail to the receivers or not")
    parser.add_argument( "-f", "--folder", action="store", dest="folder",
            default="", help="assign a folder to store the results")
    parser.add_argument("-C", "--config", action="store", dest="config_file",
            default="", help="specify the location of config file")
    parser.add_argument("-l", "--benchmarklist", action="store_true", dest="benchmarklist", default=False,
                        help="display support benchmark list")
    parser.add_argument("-d", "--debug", action="store_true", dest="debug", default=False,help="debug mode")

    args = parser.parse_args()
    start_time = datetime.datetime.now()

    if args.debug:
        logging.basicConfig(level=logging.DEBUG)
    else:
        logging.basicConfig(level=logging.INFO)

    config_files = os.path.join(caliper_path.config_files.config_dir, 'cases_config.json')
    fp = open(config_files, 'r')
    tool_list = []
    case_list = yaml.load(fp.read())
    dimension_list = {}
    for dimension in case_list:
        dimension_list[dimension] = []
        for i in range(len(case_list[dimension])):
            for tool in case_list[dimension][i]:
                dimension_list[dimension].append(tool)
    if args.benchmarklist:
        for dimen in dimension_list:
            print dimen + ':'
            for tool in dimension_list[dimen]:
                print '    '+tool
        sys.exit()

    f_option = 0
    if args.folder:
        f_option = 1
        caliper_path.folder_ope.workspace = args.folder
        caliper_path.folder_ope.set_up_path()
        from caliper.client.shared.caliper_path import folder_ope as FOLDER
        if os.path.exists(FOLDER.caliper_log_file):
            fp = open(FOLDER.caliper_log_file,'a+')
            fp.write("re-execution with -f .It may be execution of all the tools or some specific tools as specified in the config file \n")
            fp.close()

    if not os.path.exists(caliper_path.folder_ope.workspace):
        try:
            os.makedirs(caliper_path.folder_ope.workspace)
        except Exception as e:
            print e
            sys.exit(1)

    if args.config_file:
        caliper_path.config_files.name = args.config_file
        caliper_path.config_files.setup_path()
        settings.set_config_files(os.path.join(
                                caliper_path.config_files.config_dir,
                                'client_config.cfg'
                                ))
    else:
        caliper_path.config_files.name = caliper_path.folder_ope.workspace
        caliper_path.config_files.setup_path()
        if not os.path.exists(caliper_path.folder_ope.workspace + "/config"):
            shutil.copytree(caliper_path.caliper_config_file, caliper_path.folder_ope.workspace + "/config")

        settings.set_config_files(os.path.join(
            caliper_path.config_files.config_dir,
            'client_config.cfg'
        ))

    caliper_path.create_dir()

    # if args.webpage != True:
    remote_host = get_remote_host()

    if args.build or args.run:
        if args.build:
            try:
                clear = 0
                if args.cleanbuild:
                    clear = 1
                result1 = build_all_tests(remote_host,f_option,clear)
                if result1:
                    sys.exit()
            except Exception, e:
                raise

        if args.run:
            try:
                result2 = run_caliper(f_option)
                if result2:
                    sys.exit()

            except Exception:
                raise

            end_time = datetime.datetime.now()
            interval = end_time - start_time
            try:
                summary.output_summary_info(remote_host, interval.seconds)
            except Exception, e:
                raise e

    if args.parse:
        try:
            result2 = parser_caliper_logs(f_option)
            if result2:
               sys.exit()
            result2 = test_run.compute_caliper_logs(remote_host,1)
        except Exception:
            raise
    if args.score:
        try:
            result2 = test_run.compute_caliper_logs(remote_host,2)
            if intermediate:
                parser_caliper(remote_host)
            # copy yaml to corresponding dirs under caliper_out
            copy_yaml(remote_host)
        except Exception as e:
            print e
            pass

    if args.webpage and not args.send_email:
        try:
            populate_excels()

            # filter all the test cases to get only the common test cases passed in all the plaforms. other test cases marked as INVALID.
            flag = normalize_scores()

            # Reads one value from all the plaforms and then compares this values with each other to rank them. This is done for all the values in the yaml files. These new values are writed to _score_post.yaml.
            write_results.normalize_caliper()

            # computes the score i.e TOTAL_SCORE in the form of 100% for each section in the newly generated _post.yaml and _post.json files. _post.yaml file is to be used for image creation and _post.json file is to be used for table creation in HTML report.
            normalize.normalise()
        except Exception as e:
            print e
            # sys.exit()
        # flag = generate_web_tar()
        try:
            local_url = "127.0.0.1:8000"
            logging.info("local upload start")
            upload.upload_result(remote_host,local_url)
            logging.info("local upload end")
        except:
            pass
        try:
            remote_url = get_remote_url()
            if remote_url:
                remote_url += ":8000"
                logging.info("remote upload start")
                upload.upload_result(remote_host,remote_url)
                logging.info("remote upload end")
        except:
            pass

    if args.webpage and args.send_email:
        # flag = generate_web_tar()
        result_path = os.path.join(caliper_path.folder_ope.results_dir,
                'test_results.tar.gz')
        if os.path.exists(result_path):
            send_mails.send_mails(result_path)
            print("\n'test_results.tar.gz file has been sent, please check the mail\n")
            sys.exit()
        if not os.path.exists(result_path):
            try:
                os.makedirs(caliper_path.folder_ope.workspace)
            except Exception as e:
                print("\nCan't able to send the mail as 'test_results.tar.gz' file is not created\n")
                sys.exit()

    if args.folder and args.send_email:
        result_path = os.path.join(caliper_path.folder_ope.workspace, caliper_path.folder_ope.name,
                                   'results_summary.log')
        if os.path.exists(result_path):
             send_mails.send_mails(result_path)
             print("\n'results_summary.log' file has been sent, please check the mail\n")
             sys.exit()
        if not os.path.exists(result_path):
            try:
                os.makedirs(caliper_path.folder_ope.workspace)
            except Exception as e:
                print("\nCan't able to send the mail as 'results_summary.log' file is not present\n ")
                sys.exit()

    if not args.folder and args.send_email:
        result_path = os.path.join(caliper_path.folder_ope.workspace, caliper_path.folder_ope.name,
                                   'results_summary.log')
        if os.path.exists(result_path):
            send_mails.send_mails(result_path)
            print("\n'results_summary.log' file has been sent , please check the mail\n")
            sys.exit()
        if not os.path.exists(result_path):
            try:
                os.makedirs(caliper_path.folder_ope.workspace)
            except Exception as e:
                print("\n Can't able to send the mail as 'results_summary.log' file is not present\n ")
                sys.exit()

    if not args.webpage and args.send_email:
        current_path = os.getcwd()
        flag = 0
        for root, _, files in sorted(os.walk(current_path)):
            for name in files:
                if re.search('test_results.tar.gz', name):
                    result_path = os.path.join(root, name)
                    flag = 1
                    break
            if flag == 1:
                break
        if os.path.exists(result_path):
            send_mails.send_mails(result_path)

